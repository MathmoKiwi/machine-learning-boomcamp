{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9ba520-aaa5-475f-921b-3579111ee57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each feature:\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "balance      0\n",
      "housing      0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "file_path = 'bank-full.csv'\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Select the specified columns\n",
    "columns_to_use = [\n",
    "    'age', 'job', 'marital', 'education', 'balance', 'housing', 'contact', \n",
    "    'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y'\n",
    "]\n",
    "df_selected = df[columns_to_use]\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df_selected.isnull().sum()\n",
    "\n",
    "# Display the missing values\n",
    "print(\"Missing values in each feature:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c3dd4-a88d-4db1-94dd-57b097d47063",
   "metadata": {},
   "source": [
    "**Question 1:** \n",
    "What is the most frequent observation (mode) for the column education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff23d9f8-cbeb-4f62-8033-8fbce00b9ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent observation (mode) for the education column is: secondary\n"
     ]
    }
   ],
   "source": [
    "# Find the mode of the 'education' column\n",
    "education_mode = df_selected['education'].mode()[0]\n",
    "\n",
    "# Display the result\n",
    "print(f\"The most frequent observation (mode) for the education column is: {education_mode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc897aa-a348-4097-9b4b-7f1e5369387c",
   "metadata": {},
   "source": [
    "**Question 2:** What are the two features that have the biggest correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96829d3b-aa8d-470c-995a-7516fcc514fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix:\n",
      "               age   balance       day  duration  campaign     pdays  previous\n",
      "age       1.000000  0.097783 -0.009120 -0.004648  0.004760 -0.023758  0.001288\n",
      "balance   0.097783  1.000000  0.004503  0.021560 -0.014578  0.003435  0.016674\n",
      "day      -0.009120  0.004503  1.000000 -0.030206  0.162490 -0.093044 -0.051710\n",
      "duration -0.004648  0.021560 -0.030206  1.000000 -0.084570 -0.001565  0.001203\n",
      "campaign  0.004760 -0.014578  0.162490 -0.084570  1.000000 -0.088628 -0.032855\n",
      "pdays    -0.023758  0.003435 -0.093044 -0.001565 -0.088628  1.000000  0.454820\n",
      "previous  0.001288  0.016674 -0.051710  0.001203 -0.032855  0.454820  1.000000\n",
      "The two features with the biggest correlation are: ('pdays', 'previous') with a correlation of 0.45\n"
     ]
    }
   ],
   "source": [
    "# Select numerical features from the dataset\n",
    "numerical_features = df_selected[['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']]\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numerical_features.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Find the pair of features with the highest correlation\n",
    "correlation_pairs = correlation_matrix.unstack().sort_values(kind=\"quicksort\", ascending=False)\n",
    "\n",
    "# Exclude the diagonal (correlation of features with themselves)\n",
    "correlation_pairs = correlation_pairs[correlation_pairs < 1]\n",
    "\n",
    "# Display the two features with the highest correlation\n",
    "highest_correlation = correlation_pairs.idxmax()\n",
    "highest_correlation_value = correlation_pairs.max()\n",
    "\n",
    "print(f\"The two features with the biggest correlation are: {highest_correlation} with a correlation of {highest_correlation_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb34bb3-687b-45c8-a144-63a4f434f1c6",
   "metadata": {},
   "source": [
    "**Target encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "613633d9-e5d0-4aa6-99b7-0d65caf2fc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'yes' with 1 and 'no' with 0 in the 'y' column\n",
    "df_selected.loc[:, 'y'] = df_selected['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Display the first few rows to confirm the encoding\n",
    "df_selected[['y']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2cfdde1-bafc-4992-ba11-6c37f60d7a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "no     39922\n",
       "yes     5289\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique values in the 'y' column before encoding\n",
    "df_selected_original = pd.read_csv(file_path, sep=';')\n",
    "df_selected_original['y'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5e494b8-6f5e-4fc4-b6b6-f97d668ad68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'y' column: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the 'y' column\n",
    "unique_values = df_selected['y'].unique()\n",
    "\n",
    "# Display the unique values\n",
    "print(\"Unique values in the 'y' column:\", unique_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f2ae07-6187-443c-8d41-506d0dbc5341",
   "metadata": {},
   "source": [
    "**Split the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f5a58d4-5659-44bf-8805-aad0f748cd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (27126, 16) (27126,)\n",
      "Validation set shape: (9042, 16) (9042,)\n",
      "Test set shape: (9043, 16) (9043,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate the features (X) from the target (y)\n",
    "X = df_selected.drop(columns=['y'])\n",
    "y = df_selected['y']\n",
    "\n",
    "# First, split into 60% training and 40% remaining data\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Then, split the remaining 40% into 20% validation and 20% test data\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the shape of each split to confirm\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb2fbd-40aa-4926-ad19-10098a8ef20e",
   "metadata": {},
   "source": [
    "**Question 3:** Which variable has the biggest mutual information score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bb12ee8-2a32-4752-86bc-c523f5e3e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores:\n",
      "Variable\n",
      "poutcome     0.04\n",
      "housing      0.02\n",
      "education    0.01\n",
      "contact      0.01\n",
      "Name: Mutual Information Score, dtype: float64\n",
      "\n",
      "The variable with the highest mutual information score is 'poutcome' with a score of 0.04.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "\n",
    "# Select categorical features from the training set\n",
    "categorical_features = ['contact', 'education', 'housing', 'poutcome']\n",
    "X_train_categorical = X_train[categorical_features]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_train_encoded = pd.get_dummies(X_train_categorical, drop_first=True)\n",
    "\n",
    "# Calculate the mutual information scores\n",
    "mi_scores = mutual_info_classif(X_train_encoded, y_train, random_state=42)\n",
    "\n",
    "# Create a DataFrame to display the scores alongside the features\n",
    "mi_scores_df = pd.DataFrame({\n",
    "    'Feature': X_train_encoded.columns,\n",
    "    'Mutual Information Score': mi_scores\n",
    "})\n",
    "\n",
    "# Extract the original categorical variable names by splitting on the first underscore\n",
    "mi_scores_df['Variable'] = mi_scores_df['Feature'].str.split('_').str[0]\n",
    "\n",
    "# Group by the original categorical variables and sum their MI scores\n",
    "mi_scores_summed = mi_scores_df.groupby('Variable')['Mutual Information Score'].sum()\n",
    "\n",
    "# Round the scores to 2 decimals\n",
    "mi_scores_summed = mi_scores_summed.round(2)\n",
    "\n",
    "# Sort the scores in descending order to find the variable with the highest MI score\n",
    "mi_scores_summed_sorted = mi_scores_summed.sort_values(ascending=False)\n",
    "\n",
    "# Display the mutual information scores\n",
    "print(\"Mutual Information Scores:\")\n",
    "print(mi_scores_summed_sorted)\n",
    "\n",
    "# Identify the variable with the highest mutual information score\n",
    "highest_mi_variable = mi_scores_summed_sorted.idxmax()\n",
    "highest_mi_score = mi_scores_summed_sorted.max()\n",
    "\n",
    "print(f\"\\nThe variable with the highest mutual information score is '{highest_mi_variable}' with a score of {highest_mi_score}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175df9a7-e5be-4a07-aed4-27a6540aaa64",
   "metadata": {},
   "source": [
    "**Question 4:** What accuracy did you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86c4d79e-355c-4ecd-a34a-335eed0a4013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in training set after conversion:\n",
      "age                    int64\n",
      "default                int64\n",
      "balance                int64\n",
      "loan                   int64\n",
      "day                    int64\n",
      "duration               int64\n",
      "campaign               int64\n",
      "pdays                  int64\n",
      "previous               int64\n",
      "job_blue-collar         bool\n",
      "job_entrepreneur        bool\n",
      "job_housemaid           bool\n",
      "job_management          bool\n",
      "job_retired             bool\n",
      "job_self-employed       bool\n",
      "job_services            bool\n",
      "job_student             bool\n",
      "job_technician          bool\n",
      "job_unemployed          bool\n",
      "job_unknown             bool\n",
      "marital_married         bool\n",
      "marital_single          bool\n",
      "education_secondary     bool\n",
      "education_tertiary      bool\n",
      "education_unknown       bool\n",
      "housing_yes             bool\n",
      "contact_telephone       bool\n",
      "contact_unknown         bool\n",
      "month_aug               bool\n",
      "month_dec               bool\n",
      "month_feb               bool\n",
      "month_jan               bool\n",
      "month_jul               bool\n",
      "month_jun               bool\n",
      "month_mar               bool\n",
      "month_may               bool\n",
      "month_nov               bool\n",
      "month_oct               bool\n",
      "month_sep               bool\n",
      "poutcome_other          bool\n",
      "poutcome_success        bool\n",
      "poutcome_unknown        bool\n",
      "dtype: object\n",
      "The accuracy on the validation dataset is: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: One-hot encode categorical variables in the training and validation sets\n",
    "categorical_features = ['job', 'marital', 'education', 'housing', 'contact', 'month', 'poutcome']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_features, drop_first=True)\n",
    "X_val_encoded = pd.get_dummies(X_val, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Ensure the same columns are present in both the training and validation sets (in case any categories are missing)\n",
    "X_val_encoded = X_val_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# Convert 'default' and 'loan' columns from 'yes'/'no' to 1/0\n",
    "X_train_encoded['default'] = X_train_encoded['default'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "X_train_encoded['loan'] = X_train_encoded['loan'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "X_val_encoded['default'] = X_val_encoded['default'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "X_val_encoded['loan'] = X_val_encoded['loan'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Check the data types after conversion\n",
    "print(\"Data types in training set after conversion:\")\n",
    "print(X_train_encoded.dtypes)\n",
    "\n",
    "# Step 2: Train the logistic regression model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Step 3: Predict and calculate the accuracy on the validation set\n",
    "y_val_pred = model.predict(X_val_encoded)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Round the accuracy to 2 decimal places\n",
    "accuracy_rounded = round(accuracy, 2)\n",
    "\n",
    "# Display the result\n",
    "print(f\"The accuracy on the validation dataset is: {accuracy_rounded}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532bc807-68a3-4232-88b8-d814e35e76c4",
   "metadata": {},
   "source": [
    "**Question 5:** Which feature has the smallest difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c32bdc8a-16b7-4637-8c01-4b48ccc6f7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy differences for each feature:\n",
      "age: 0.0\n",
      "balance: -0.0003\n",
      "marital: -0.0012\n",
      "previous: -0.0012\n",
      "\n",
      "The feature with the smallest difference in accuracy is 'marital' with a difference of -0.0012.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to drop all columns related to a specific feature (for one-hot encoded variables)\n",
    "def drop_feature_columns(feature, X):\n",
    "    # Use regular expressions to find all columns related to the feature\n",
    "    columns_to_drop = [col for col in X.columns if re.match(f\"^{feature}_\", col) or col == feature]\n",
    "    return X.drop(columns=columns_to_drop)\n",
    "\n",
    "# Step 1: Train a baseline model with all features\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict and calculate the baseline accuracy on the validation set\n",
    "y_val_pred = model.predict(X_val_encoded)\n",
    "baseline_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Initialize a dictionary to store the accuracies without each feature\n",
    "accuracy_diffs = {}\n",
    "\n",
    "# List of features to test (age, balance, marital, previous)\n",
    "features_to_test = ['age', 'balance', 'marital', 'previous']\n",
    "\n",
    "# Step 2: Iterate over each feature, exclude it, and train a model without it\n",
    "for feature in features_to_test:\n",
    "    # Drop the feature and all associated one-hot encoded columns\n",
    "    X_train_without_feature = drop_feature_columns(feature, X_train_encoded)\n",
    "    X_val_without_feature = drop_feature_columns(feature, X_val_encoded)\n",
    "    \n",
    "    # Train a new model without the selected feature\n",
    "    model_without_feature = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_without_feature.fit(X_train_without_feature, y_train)\n",
    "    \n",
    "    # Predict and calculate the accuracy on the validation set\n",
    "    y_val_pred_without_feature = model_without_feature.predict(X_val_without_feature)\n",
    "    accuracy_without_feature = accuracy_score(y_val, y_val_pred_without_feature)\n",
    "    \n",
    "    # Calculate the difference between the baseline accuracy and the accuracy without the feature\n",
    "    accuracy_diff = baseline_accuracy - accuracy_without_feature\n",
    "    \n",
    "    # Store the difference in the dictionary\n",
    "    accuracy_diffs[feature] = accuracy_diff\n",
    "\n",
    "# Step 3: Display the differences in accuracy for each feature\n",
    "print(\"Accuracy differences for each feature:\")\n",
    "for feature, diff in accuracy_diffs.items():\n",
    "    print(f\"{feature}: {round(diff, 4)}\")\n",
    "\n",
    "# Step 4: Find the feature with the smallest difference\n",
    "least_useful_feature = min(accuracy_diffs, key=accuracy_diffs.get)\n",
    "smallest_difference = accuracy_diffs[least_useful_feature]\n",
    "\n",
    "print(f\"\\nThe feature with the smallest difference in accuracy is '{least_useful_feature}' with a difference of {round(smallest_difference, 4)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab1d211-728c-49e9-a40c-40b8aefa0413",
   "metadata": {},
   "source": [
    "**Question 6:** Which of these C leads to the best accuracy on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e21821fa-1548-43b8-bfd7-3e1f3188ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for each C value:\n",
      "C = 0.01: Accuracy = 0.897\n",
      "C = 0.1: Accuracy = 0.899\n",
      "C = 1: Accuracy = 0.9\n",
      "C = 10: Accuracy = 0.901\n",
      "C = 100: Accuracy = 0.901\n",
      "\n",
      "The value of C that leads to the best accuracy on the validation set is 10 with an accuracy of 0.901.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of C values to test\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Dictionary to store the accuracies for each C value\n",
    "accuracies = {}\n",
    "\n",
    "# Iterate over each value of C\n",
    "for C in C_values:\n",
    "    # Train the logistic regression model with the current value of C\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # Predict and calculate the accuracy on the validation set\n",
    "    y_val_pred = model.predict(X_val_encoded)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Round the accuracy to 3 decimal places\n",
    "    accuracy_rounded = round(accuracy, 3)\n",
    "    \n",
    "    # Store the accuracy in the dictionary\n",
    "    accuracies[C] = accuracy_rounded\n",
    "\n",
    "# Display the accuracies for each value of C\n",
    "print(\"Validation accuracy for each C value:\")\n",
    "for C, accuracy in accuracies.items():\n",
    "    print(f\"C = {C}: Accuracy = {accuracy}\")\n",
    "\n",
    "# Find the value of C with the highest accuracy\n",
    "best_C = max(accuracies, key=accuracies.get)\n",
    "best_accuracy = accuracies[best_C]\n",
    "\n",
    "print(f\"\\nThe value of C that leads to the best accuracy on the validation set is {best_C} with an accuracy of {best_accuracy}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48a7e052-32e8-472e-b749-4da3f7d240bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on validation set using C = 0.01 is 0.899.\n",
      "The accuracy on validation set using C = 0.1 is 0.900.\n",
      "The accuracy on validation set using C = 1 is 0.901.\n",
      "The accuracy on validation set using C = 10 is 0.901.\n",
      "The accuracy on validation set using C = 100 is 0.901.\n",
      "\n",
      "The value of C that leads to the best accuracy on the validation set is 1 with an accuracy of 0.901.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# List of C values to test\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Initialize a list to store the accuracies for each C value\n",
    "accuracies = []\n",
    "\n",
    "# Step 1: Convert training and validation sets to dictionary format\n",
    "categorical_features = ['job', 'marital', 'education', 'housing', 'contact', 'month', 'poutcome']\n",
    "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Convert the selected features to dictionaries for DictVectorizer\n",
    "train_dicts = X_train[categorical_features + numerical_features].to_dict(orient='records')\n",
    "val_dicts = X_val[categorical_features + numerical_features].to_dict(orient='records')\n",
    "\n",
    "# Step 2: Use DictVectorizer to convert dictionaries to numeric arrays\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Fit on the training data and transform both training and validation sets\n",
    "X_train_transformed = dv.fit_transform(train_dicts)\n",
    "X_val_transformed = dv.transform(val_dicts)\n",
    "\n",
    "# Step 3: Iterate over each value of C and train a logistic regression model\n",
    "for C in C_values:\n",
    "    # Train the logistic regression model with the current value of C\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    \n",
    "    # Predict probabilities on the validation set and classify using a 0.5 threshold\n",
    "    y_val_pred_prob = model.predict_proba(X_val_transformed)[:, 1]\n",
    "    y_val_pred = (y_val_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "    # Calculate accuracy on the validation set\n",
    "    accuracy = (y_val == y_val_pred).mean()\n",
    "    \n",
    "    # Append the rounded accuracy to the list\n",
    "    accuracies.append(round(accuracy, 3))\n",
    "\n",
    "    # Print the accuracy for the current value of C\n",
    "    print(f\"The accuracy on validation set using C = {C} is {accuracy:.3f}.\")\n",
    "\n",
    "# Step 4: Find the best value of C based on accuracy\n",
    "best_C_index = accuracies.index(max(accuracies))\n",
    "best_C = C_values[best_C_index]\n",
    "best_accuracy = accuracies[best_C_index]\n",
    "\n",
    "print(f\"\\nThe value of C that leads to the best accuracy on the validation set is {best_C} with an accuracy of {best_accuracy:.3f}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

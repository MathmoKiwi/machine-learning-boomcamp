{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf17d65-396f-4410-a7ea-31b7e7cddc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests[socks]->gdown) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\t-bao\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm->gdown) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4130f0da-8d9f-4199-8270-0f50a5fbbfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_RGUQe397BeGEmCY9BEHX081lAleMnmw\n",
      "To: C:\\Users\\T-bao\\bank-full.csv\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.61M/4.61M [00:00<00:00, 6.21MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bank-full.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Google Drive file ID\n",
    "file_id = \"1_RGUQe397BeGEmCY9BEHX081lAleMnmw\"\n",
    "# Construct the download URL\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "# Output file path\n",
    "output = \"bank-full.csv\"\n",
    "\n",
    "# Download the file\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888cf84d-a376-48fe-b622-507c08f0fbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with semicolon as the delimiter\n",
    "df = pd.read_csv(\"bank-full.csv\", delimiter=';')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6af708-2b75-4a06-8ddb-453563f3ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'age', 'job', 'marital', 'education', 'balance', 'housing', 'contact', \n",
    "    'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y'\n",
    "]\n",
    "\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89e6853-d70d-44c9-8170-c45cae54ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)  # 0.25 * 0.8 = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091940cb-d787-4f89-8390-5a709cf54c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in 'y' before mapping\n",
    "print(df_train['y'].unique())\n",
    "unique_values = df_train['y'].unique()\n",
    "if set(unique_values) == {'yes', 'no'}:\n",
    "    # Perform mapping\n",
    "    df_train['y'] = df_train['y'].map({'yes': 1, 'no': 0})\n",
    "else:\n",
    "    print('y is already mapped to numeric values.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19e570de-dc2f-409e-9f0e-f65058554801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28481d2a-3265-498a-a317-8920b89f9dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for balance: 0.589\n",
      "AUC for day: 0.526\n",
      "AUC for duration: 0.815\n",
      "AUC for previous: 0.599\n"
     ]
    }
   ],
   "source": [
    "numerical_vars = ['balance', 'day', 'duration', 'previous']\n",
    "for var in numerical_vars:\n",
    "    auc = roc_auc_score(df_train['y'], df_train[var])\n",
    "    # If AUC < 0.5, invert the variable\n",
    "    if auc < 0.5:\n",
    "        auc = roc_auc_score(df_train['y'], -df_train[var])\n",
    "    print(f'AUC for {var}: {auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07fce6ae-6716-4f34-bdbc-37279345fb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the original dataset: 45211\n",
      "Total NaN values in 'y': 0\n"
     ]
    }
   ],
   "source": [
    "# Check if the original 'y' column has any NaN values\n",
    "print(f\"Total rows in the original dataset: {len(df)}\")\n",
    "print(f\"Total NaN values in 'y': {df['y'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1719570a-9fc6-48f8-8530-9826c92ecfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'y' after mapping: [0 1]\n",
      "Missing values in 'y' in the training set: 0\n",
      "Missing values in 'y' in the validation set: 0\n",
      "X_train shape: (27126, 47)\n",
      "X_val shape: (9042, 47)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Mapping 'yes'/'no' in 'y' to 1/0 and verify the mapping\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# Ensure the mapping has been applied correctly\n",
    "print(f\"Unique values in 'y' after mapping: {df['y'].unique()}\")\n",
    "\n",
    "# Step 2: Split the dataset into train and validation sets\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=1)\n",
    "\n",
    "# Step 3: Ensure there are no NaN values in the target column after splitting\n",
    "print(f\"Missing values in 'y' in the training set: {df_train['y'].isna().sum()}\")\n",
    "print(f\"Missing values in 'y' in the validation set: {df_val['y'].isna().sum()}\")\n",
    "\n",
    "# Step 4: Proceed with extracting 'y' and removing it from the feature set\n",
    "y_train = df_train['y'].values\n",
    "y_val = df_val['y'].values\n",
    "\n",
    "# Remove 'y' from the features\n",
    "df_train = df_train.drop(columns=['y'])\n",
    "df_val = df_val.drop(columns=['y'])\n",
    "\n",
    "# Step 5: Convert the data into dictionaries and one-hot encode\n",
    "train_dicts = df_train.to_dict(orient='records')\n",
    "val_dicts = df_val.to_dict(orient='records')\n",
    "\n",
    "# Step 6: One-hot encoding with DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b281e013-fefe-46fb-8422-e3ebc1da6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Check for NaN values in y and handle missing values in X\n",
    "# Ensure 'y_train' does not contain NaN values by dropping rows with missing targets\n",
    "nan_count = np.isnan(y_train).sum()\n",
    "\n",
    "if nan_count > 0:\n",
    "    print(f\"Dropping {nan_count} rows where the target 'y' is NaN\")\n",
    "    # Drop rows where 'y' is NaN\n",
    "    X_train_cleaned = X_train[~np.isnan(y_train)]\n",
    "    y_train_cleaned = y_train[~np.isnan(y_train)]\n",
    "else:\n",
    "    X_train_cleaned = X_train\n",
    "    y_train_cleaned = y_train\n",
    "\n",
    "# Step 2: If there are missing values in X_train, I might use imputation\n",
    "imputer = SimpleImputer(strategy='mean')  # or strategy='median',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd9879c0-9c86-464b-93b5-aaf00e89b20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the training dataset: 27126\n",
      "Rows with NaN values in 'y': 0\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of rows in the training set before dropping NaN values\n",
    "total_rows = len(df_train)\n",
    "print(f\"Total rows in the training dataset: {total_rows}\")\n",
    "print(f\"Rows with NaN values in 'y': {nan_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
